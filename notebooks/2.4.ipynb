{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/solomontessema/building-agentic-ai/blob/main/notebooks/2.4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BQRkf3HklNe"
      },
      "source": [
        "<table>\n",
        "  <tr>\n",
        "    <td><img src=\"https://ionnova.com/img/ionnova_logo_name_2.png\" width=\"120px\"></td>\n",
        "    <td><h1>Building a Conversational Agent</h1></td>\n",
        "  </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSQaUTz_k6qO"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langchain==1.1.0 langchain-openai==1.1.0 python-dotenv==1.1.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NZ2_4NqzCx3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import langgraph\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.tools import Tool\n",
        "from langchain.agents import create_agent\n",
        "from langchain.agents.middleware import SummarizationMiddleware\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "\n",
        "def check_inventory(product_name: str) -> str:\n",
        "    product_name = product_name.lower()\n",
        "    if \"laptop\" in product_name:\n",
        "        return \"The Pro-X Laptop has 15 units in stock.\"\n",
        "    elif \"monitor\" in product_name:\n",
        "        return \"The Ultra HD Monitor is currently out of stock.\"\n",
        "    else:\n",
        "        return f\"Could not find inventory details for {product_name}.\"\n",
        "\n",
        "check_inventory_tool = Tool(\n",
        "    name=\"check_inventory\",\n",
        "    func=check_inventory,\n",
        "    description = \"Returns the current stock count for a given product name.\"\n",
        ")\n",
        "\n",
        "summarization_middleware = SummarizationMiddleware(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    trigger=('tokens', 1000),\n",
        "    keep=('messages', 5),\n",
        ")\n",
        "\n",
        "conversational_agent = create_agent(\n",
        "    model=llm,\n",
        "    tools=[check_inventory_tool],\n",
        "    system_prompt=\"You are a helpful and detailed customer service agent. You must use your tools whenever necessary to answer questions about inventory.\",\n",
        "    middleware=[summarization_middleware],\n",
        "    checkpointer=InMemorySaver(),\n",
        ")\n",
        "\n",
        "\n",
        "def run_chat(user_input: str):\n",
        "    config = {\"configurable\": {\"thread_id\": \"1001\"}}\n",
        "    response = conversational_agent.invoke(\n",
        "        {\"messages\": [HumanMessage(content=user_input)]},\n",
        "        config=config,\n",
        "    )\n",
        "\n",
        "    ai_response = response[\"messages\"][-1].content\n",
        "    return ai_response\n",
        "\n",
        "\n",
        "while True:\n",
        "    user_question = input(\"Enter your message: \")\n",
        "    if user_question.lower() == \"exit\":\n",
        "        break\n",
        "    response = run_chat(user_question)\n",
        "    print(response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

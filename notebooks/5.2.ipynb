{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZ2+bwxQbIGKUU/iUPKMKu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/solomontessema/building-ai-agents/blob/main/notebooks/5.2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mS80ofB_mhjk"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langchain==1.1.0  langchain-community==0.4.1 \"unstructured[all-docs]\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_core.documents import Document\n",
        "import os\n",
        "\n",
        "# Create a directory\n",
        "os.makedirs(\"docs\", exist_ok=True)\n",
        "\n",
        "# Write some sample content to the file\n",
        "content = \"\"\"\n",
        "LangGraph is a library for building stateful, multi-agent applications with LLMs.\n",
        "It extends the LangChain Expression Language (LCEL) by allowing for cycles and\n",
        "persistence in your agent workflows. Unlike linear chains, LangGraph uses\n",
        "nodes and edges to create complex, iterative processes.\n",
        "RecursiveCharacterTextSplitter is a text‑splitting utility in LangChain that breaks\n",
        "large documents into smaller, semantically coherent chunks by recursively trying\n",
        "larger separators first (paragraphs → sentences → words → characters).\n",
        "It’s the most commonly recommended splitter for RAG pipelines because it preserves\n",
        "meaning better than naive fixed‑size splits.\n",
        "\"\"\"\n",
        "\n",
        "with open(\"docs/langgraph_intro.txt\", \"w\") as f:\n",
        "    f.write(content)\n",
        "\n",
        "print(\"File created successfully!\")\n",
        "\n",
        "\n",
        "# Load text documents from a directory\n",
        "loader = DirectoryLoader(\"docs/\", glob=\"**/*.txt\")\n",
        "documents = loader.load()\n",
        "\n",
        "# Clean whitespace and normalize content\n",
        "cleaned_docs = [\n",
        "    Document(page_content=doc.page_content.strip(), metadata=doc.metadata)\n",
        "    for doc in documents\n",
        "]\n",
        "\n",
        "# Split into overlapping chunks\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "chunks = splitter.split_documents(cleaned_docs)\n",
        "\n",
        "# Tag metadata\n",
        "for chunk in chunks:\n",
        "    chunk.metadata[\"corpus\"] = \"internal_knowledge_base\"\n",
        "\n",
        "print(f\"Loaded {len(documents)} documents, split into {len(chunks)} chunks.\")\n"
      ],
      "metadata": {
        "id": "qHzjV_Cvmi23"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}